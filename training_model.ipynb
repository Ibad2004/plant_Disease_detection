{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a38d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e274af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef723561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO REMOVE CORRUPTED IMAGES\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "RAW_DATASET_DIR = 'raw_dataset'  # Your original dataset folder\n",
    "\n",
    "def remove_corrupted_images(dataset_dir):\n",
    "    removed_files = []\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for img_file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()  # Verify if image is corrupted\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f\"Removing corrupted image: {img_path}\")\n",
    "                os.remove(img_path)\n",
    "                removed_files.append(img_path)\n",
    "    return removed_files\n",
    "\n",
    "removed = remove_corrupted_images(RAW_DATASET_DIR)\n",
    "print(f\"Total corrupted images removed: {len(removed)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038282a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CLEAN LABELS\n",
    "import re\n",
    "\n",
    "def check_class_names(dataset_dir):\n",
    "    invalid_names = []\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        # Allow only alphanumeric, underscore, and spaces\n",
    "        if not re.match(r'^[\\w\\s]+$', class_name):\n",
    "            invalid_names.append(class_name)\n",
    "    return invalid_names\n",
    "\n",
    "invalid_classes = check_class_names(RAW_DATASET_DIR)\n",
    "if invalid_classes:\n",
    "    print(\"Invalid class folder names detected:\")\n",
    "    for name in invalid_classes:\n",
    "        print(f\" - {name}\")\n",
    "else:\n",
    "    print(\"All class folder names are clean!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6fec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing Images and Converting to JPEG\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_and_convert(dataset_dir, output_dir, target_size):\n",
    "    total_images = 0\n",
    "    total_skipped = 0\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        processed_class_path = os.path.join(output_dir, class_name.replace(' ', '_'))\n",
    "        os.makedirs(processed_class_path, exist_ok=True)\n",
    "\n",
    "        count = 0\n",
    "        for img_name in os.listdir(class_path):\n",
    "            src_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                with Image.open(src_path) as img:\n",
    "                    img = img.convert('RGB')\n",
    "                    img = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "                    base_name = os.path.splitext(img_name)[0]\n",
    "                    save_path = os.path.join(processed_class_path, base_name + '.jpg')\n",
    "                    img.save(save_path, 'JPEG', quality=95)\n",
    "                count += 1\n",
    "                total_images += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping invalid image {src_path}: {e}\")\n",
    "                total_skipped += 1\n",
    "        print(f\"Processed {count} images in class '{class_name}'\")\n",
    "\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Total images skipped: {total_skipped}\")\n",
    "\n",
    "# Example usage:\n",
    "resize_and_convert('raw_dataset', 'processed_dataset', (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4735ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_images(dataset_dir):\n",
    "    total_images = 0\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"Class '{class_name}': {num_images} images\")\n",
    "        total_images += num_images\n",
    "    print(f\"Total images in dataset: {total_images}\")\n",
    "    return total_images\n",
    "\n",
    "count_images('processed_dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82db2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_images(dataset_dir):\n",
    "    total_images = 0\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        print(f\"Class '{class_name}': {num_images} images\")\n",
    "        total_images += num_images\n",
    "    print(f\"Total images in dataset: {total_images}\")\n",
    "    return total_images\n",
    "\n",
    "count_images('raw_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "PROCESSED_DATASET_DIR = 'processed_dataset'  # update path if different\n",
    "\n",
    "def dhash(image, hash_size=8):\n",
    "    # Use LANCZOS resampling instead of deprecated ANTIALIAS\n",
    "    image = image.convert('L').resize((hash_size + 1, hash_size), Image.Resampling.LANCZOS)\n",
    "    pixels = list(image.getdata())\n",
    "    difference = []\n",
    "    for row in range(hash_size):\n",
    "        for col in range(hash_size):\n",
    "            left_pixel = pixels[row * (hash_size + 1) + col]\n",
    "            right_pixel = pixels[row * (hash_size + 1) + col + 1]\n",
    "            difference.append(left_pixel > right_pixel)\n",
    "    decimal_value = 0\n",
    "    hex_string = []\n",
    "    for index, value in enumerate(difference):\n",
    "        if value:\n",
    "            decimal_value += 2 ** (index % 8)\n",
    "        if (index % 8) == 7:\n",
    "            hex_string.append(hex(decimal_value)[2:].rjust(2, '0'))\n",
    "            decimal_value = 0\n",
    "    return ''.join(hex_string)\n",
    "\n",
    "def remove_duplicates(dataset_dir):\n",
    "    hashes = set()\n",
    "    removed_count = 0\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    h = dhash(img)\n",
    "                if h in hashes:\n",
    "                    print(f\"Duplicate found, removing: {img_path}\")\n",
    "                    os.remove(img_path)\n",
    "                    removed_count += 1\n",
    "                else:\n",
    "                    hashes.add(h)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {img_path}: {e}\")\n",
    "    return removed_count\n",
    "\n",
    "duplicates_removed = remove_duplicates(PROCESSED_DATASET_DIR)\n",
    "print(f\"Duplicates removed: {duplicates_removed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa18cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "# Set the processed dataset directory\n",
    "DATASET_DIR = 'processed_dataset'\n",
    "\n",
    "# ImageDataGenerator with augmentation settings\n",
    "augmentor = ImageDataGenerator(\n",
    "    rotation_range=25,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Initialize total counters\n",
    "total_original_images = 0\n",
    "total_augmented_images = 0\n",
    "\n",
    "# Process each class\n",
    "for class_name in os.listdir(DATASET_DIR):\n",
    "    class_path = os.path.join(DATASET_DIR, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n📁 Processing class: {class_name}\")\n",
    "    image_count = 0\n",
    "    augmented_count = 0\n",
    "\n",
    "    for img_name in os.listdir(class_path):\n",
    "        if img_name.startswith('aug_'):\n",
    "            continue  # Skip already augmented images\n",
    "\n",
    "        try:\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = load_img(img_path)\n",
    "            x = img_to_array(img)\n",
    "            x = x.reshape((1,) + x.shape)\n",
    "\n",
    "            # Generate 3 augmented images\n",
    "            i = 0\n",
    "            for batch in augmentor.flow(\n",
    "                x,\n",
    "                batch_size=1,\n",
    "                save_to_dir=class_path,\n",
    "                save_prefix='aug',\n",
    "                save_format='jpeg'\n",
    "            ):\n",
    "                i += 1\n",
    "                augmented_count += 1\n",
    "                total_augmented_images += 1\n",
    "                if i >= 3:\n",
    "                    break\n",
    "\n",
    "            image_count += 1\n",
    "            total_original_images += 1\n",
    "            print(f\"✅ Augmented 3 images for: {img_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error augmenting image {img_name}: {e}\")\n",
    "\n",
    "    print(f\"📊 Class summary — Original: {image_count}, Augmented: {augmented_count}\")\n",
    "\n",
    "print(\"\\n✅ Augmentation complete\")\n",
    "print(f\"🔢 Total original images processed: {total_original_images}\")\n",
    "print(f\"📈 Total augmented images created: {total_augmented_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc31bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define your augmentation pipeline\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1)\n",
    "])\n",
    "\n",
    "def find_minority_classes(dataset_dir, threshold=3500):\n",
    "    minority_classes = []\n",
    "    print(\"🔍 Checking classes for minority status based on threshold ≤\", threshold)\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        num_images = len([name for name in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, name))])\n",
    "        print(f\"Class '{class_name}' has {num_images} images\")\n",
    "        if num_images <= threshold:\n",
    "            minority_classes.append(class_name)\n",
    "            print(f\"✅ Class '{class_name}' marked as minority class\")\n",
    "    return minority_classes\n",
    "\n",
    "def augment_minority_classes(dataset_dir, minority_classes, augmentations_per_image=3):\n",
    "    total_original = 0\n",
    "    total_augmented = 0\n",
    "\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        if class_name not in minority_classes:\n",
    "            print(f\"⏭ Skipping majority class: {class_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n🚀 Augmenting minority class: {class_name}\")\n",
    "\n",
    "        for img_name in os.listdir(class_path):\n",
    "            if img_name.startswith('aug_') or '_aug' in img_name:\n",
    "                # Skip already augmented images to avoid duplication\n",
    "                continue\n",
    "            \n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    total_original += 1\n",
    "                    base_name, ext = os.path.splitext(img_name)\n",
    "                    \n",
    "                    for i in range(augmentations_per_image):\n",
    "                        augmented_img = augmentation(img)\n",
    "                        augmented_name = f\"{base_name}_aug{i+1}.jpg\"\n",
    "                        augmented_path = os.path.join(class_path, augmented_name)\n",
    "                        augmented_img.save(augmented_path, 'JPEG', quality=95)\n",
    "                        total_augmented += 1\n",
    "\n",
    "                    print(f\"✅ Augmented {augmentations_per_image} images for: {img_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error augmenting {img_path}: {e}\")\n",
    "\n",
    "    print(\"\\n✅ Augmentation complete\")\n",
    "    print(f\"🔢 Total original images processed for minority classes: {total_original}\")\n",
    "    print(f\"📈 Total augmented images created for minority classes: {total_augmented}\")\n",
    "\n",
    "# Set your processed dataset directory path here\n",
    "PROCESSED_DATASET_DIR = 'processed_dataset'\n",
    "\n",
    "# Step 1: Find minority classes automatically\n",
    "minority_classes = find_minority_classes(PROCESSED_DATASET_DIR, threshold=3500)\n",
    "print(\"\\n🔎 Minority classes detected:\", minority_classes)\n",
    "\n",
    "# Step 2: Augment only minority classes\n",
    "augment_minority_classes(PROCESSED_DATASET_DIR, minority_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd867c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define your augmentation pipeline\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1)\n",
    "])\n",
    "\n",
    "def find_minority_classes(dataset_dir, threshold=2000):\n",
    "    minority_classes = []\n",
    "    print(\"🔍 Checking classes for minority status based on threshold ≤\", threshold)\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        num_images = len([name for name in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, name))])\n",
    "        print(f\"Class '{class_name}' has {num_images} images\")\n",
    "        if num_images <= threshold:\n",
    "            minority_classes.append(class_name)\n",
    "            print(f\"✅ Class '{class_name}' marked as minority class\")\n",
    "    return minority_classes\n",
    "\n",
    "def augment_minority_classes(dataset_dir, minority_classes, augmentations_per_image=3):\n",
    "    total_original = 0\n",
    "    total_augmented = 0\n",
    "\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        if class_name not in minority_classes:\n",
    "            print(f\"⏭ Skipping majority class: {class_name}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n🚀 Augmenting minority class: {class_name}\")\n",
    "\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    total_original += 1\n",
    "                    base_name, ext = os.path.splitext(img_name)\n",
    "                    \n",
    "                    for i in range(augmentations_per_image):\n",
    "                        augmented_img = augmentation(img)\n",
    "                        augmented_name = f\"{base_name}_aug{i+1}.jpg\"\n",
    "                        augmented_path = os.path.join(class_path, augmented_name)\n",
    "                        augmented_img.save(augmented_path, 'JPEG', quality=95)\n",
    "                        total_augmented += 1\n",
    "\n",
    "                    print(f\"✅ Augmented {augmentations_per_image} images for: {img_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error augmenting {img_path}: {e}\")\n",
    "\n",
    "    print(\"\\n✅ Augmentation complete\")\n",
    "    print(f\"🔢 Total images processed for minority classes: {total_original}\")\n",
    "    print(f\"📈 Total augmented images created for minority classes: {total_augmented}\")\n",
    "\n",
    "# Set your processed dataset directory path here\n",
    "PROCESSED_DATASET_DIR = 'processed_dataset'\n",
    "\n",
    "# Step 1: Find minority classes automatically\n",
    "minority_classes = find_minority_classes(PROCESSED_DATASET_DIR, threshold=2000)\n",
    "print(\"\\n🔎 Minority classes detected:\", minority_classes)\n",
    "\n",
    "# Step 2: Augment only minority classes\n",
    "augment_minority_classes(PROCESSED_DATASET_DIR, minority_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8905146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ======================\n",
    "# 🔧 CONFIGURATION\n",
    "# ======================\n",
    "DATASET_DIR = 'processed_dataset'  # Folder where class subfolders are\n",
    "LABEL_MAPPING_FILE = 'label_mapping.json'\n",
    "\n",
    "def encode_labels(dataset_dir, save_mapping_file):\n",
    "    print(\"🔍 Scanning dataset for class labels...\")\n",
    "\n",
    "    # Get list of folder names (each folder = one class label)\n",
    "    class_labels = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "    print(f\"🗂 Found {len(class_labels)} classes:\")\n",
    "    for label in class_labels:\n",
    "        print(f\"  - {label}\")\n",
    "\n",
    "    # Sort labels and assign integers\n",
    "    label_to_int = {label: idx for idx, label in enumerate(sorted(class_labels))}\n",
    "    print(\"\\n🔢 Label to integer mapping:\")\n",
    "    for label, idx in label_to_int.items():\n",
    "        print(f\"  '{label}' -> {idx}\")\n",
    "\n",
    "    # Save mapping to JSON for future reference\n",
    "    with open(save_mapping_file, 'w') as f:\n",
    "        json.dump(label_to_int, f, indent=4)\n",
    "    print(f\"\\n💾 Saved label mapping to '{save_mapping_file}'\")\n",
    "\n",
    "    print(\"\\n✅ Label encoding done!\")\n",
    "    return label_to_int\n",
    "\n",
    "# Run encoding\n",
    "label_mapping = encode_labels(DATASET_DIR, LABEL_MAPPING_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# ======================\n",
    "# 🔧 CONFIGURATION\n",
    "# ======================\n",
    "DATASET_DIR = 'processed_dataset'  # Original dataset folder with class subfolders\n",
    "OUTPUT_DIR = 'dataset_split'       # Folder to create train/, val/, and test/ folders inside\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.2\n",
    "SEED = 42  # For reproducibility\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "def split_dataset(dataset_dir, output_dir, train_ratio=0.7, val_ratio=0.1, test_ratio=0.2):\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1\"\n",
    "\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    val_dir = os.path.join(output_dir, 'val')\n",
    "    test_dir = os.path.join(output_dir, 'test')\n",
    "\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        train_class_dir = os.path.join(train_dir, class_name)\n",
    "        val_class_dir = os.path.join(val_dir, class_name)\n",
    "        test_class_dir = os.path.join(test_dir, class_name)\n",
    "\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(val_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        n_total = len(images)\n",
    "        n_train = int(n_total * train_ratio)\n",
    "        n_val = int(n_total * val_ratio)\n",
    "\n",
    "        train_images = images[:n_train]\n",
    "        val_images = images[n_train:n_train + n_val]\n",
    "        test_images = images[n_train + n_val:]\n",
    "\n",
    "        for img_name in train_images:\n",
    "            shutil.copy2(os.path.join(class_path, img_name), os.path.join(train_class_dir, img_name))\n",
    "\n",
    "        for img_name in val_images:\n",
    "            shutil.copy2(os.path.join(class_path, img_name), os.path.join(val_class_dir, img_name))\n",
    "\n",
    "        for img_name in test_images:\n",
    "            shutil.copy2(os.path.join(class_path, img_name), os.path.join(test_class_dir, img_name))\n",
    "\n",
    "    print(f\"✅ Dataset split completed with {train_ratio*100}% train, {val_ratio*100}% val, and {test_ratio*100}% test.\")\n",
    "\n",
    "# Run the split\n",
    "split_dataset(DATASET_DIR, OUTPUT_DIR, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39566348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # if needed again\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # RGB\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('dataset_split/train', transform=transform)\n",
    "val_dataset = datasets.ImageFolder('dataset_split/val', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('dataset_split/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b2d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PlantDiseaseCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PlantDiseaseCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.35)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 14 * 14, 512)  # After 2 poolings, 224→112→56→28→14\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [B, 32, 112, 112]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [B, 64, 56, 56]\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # [B, 128, 28, 28]\n",
    "        x = self.pool(F.relu(self.conv4(x)))  # [B, 256, 14, 14]\n",
    "\n",
    "        x = x.view(-1, 256 * 14 * 14)         # Flatten\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5216aeda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
